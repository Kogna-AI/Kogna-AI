"""
üî• ULTIMATE Microsoft Teams ETL - FULL FEATURE SET

This is the complete, production-ready Microsoft Teams ETL with ALL improvements:

 Team and channel structure extraction
 Message content extraction
 Shared files metadata
 Thread organization
 Search-optimized text generation
 Data quality scoring
 Analytics and insights

Follows the same pattern as google_drive_etl.py, jira_etl.py, and microsoft_excel_etl.py
"""

import json
import time
import asyncio
import httpx
import logging
from typing import Dict, List, Tuple, Optional, Any
from datetime import datetime
from collections import Counter

try:
    from .base_etl import (
        safe_upload_to_bucket,
        update_sync_progress,
        queue_embedding,
        RATE_LIMIT_DELAY,
        MAX_FILE_SIZE
    )
except ImportError:
    # Fallback for testing
    RATE_LIMIT_DELAY = 0.1
    MAX_FILE_SIZE = 50_000_000
    async def safe_upload_to_bucket(*args, **kwargs): return True
    async def update_sync_progress(*args, **kwargs): pass
    async def queue_embedding(*args, **kwargs): pass

logging.basicConfig(level=logging.INFO)


# ============================================================================
# 1. DATA EXTRACTION
# ============================================================================

async def extract_team_data(
    client: httpx.AsyncClient,
    team_id: str,
    team_name: str
) -> Optional[Dict]:
    """
    Extract complete team data including channels, messages, and files.
    
    Args:
        client: HTTP client with auth headers
        team_id: Microsoft Teams team ID
        team_name: Team name for logging
        
    Returns:
        Dict with team data or None if failed
    """
    try:
        # Get channels for this team
        channels_url = f"https://graph.microsoft.com/v1.0/teams/{team_id}/channels"
        channels_response = await client.get(channels_url)
        channels_response.raise_for_status()
        channels = channels_response.json().get('value', [])
        
        logging.info(f"   ‚úì Found {len(channels)} channels")
        
        team_data = {
            'team_id': team_id,
            'team_name': team_name,
            'channels': []
        }
        
        for channel in channels:
            channel_id = channel.get('id')
            channel_name = channel.get('displayName')
            
            try:
                # Get messages from channel
                messages_url = f"https://graph.microsoft.com/v1.0/teams/{team_id}/channels/{channel_id}/messages"
                messages_response = await client.get(messages_url)
                messages_response.raise_for_status()
                messages = messages_response.json().get('value', [])
                
                channel_data = {
                    'channel_id': channel_id,
                    'channel_name': channel_name,
                    'message_count': len(messages),
                    'messages': messages
                }
                
                if messages:
                    logging.info(f"      ‚Ä¢ {channel_name}: {len(messages)} messages")
                
                # Get files shared in channel
                try:
                    files_url = f"https://graph.microsoft.com/v1.0/teams/{team_id}/channels/{channel_id}/filesFolder"
                    files_response = await client.get(files_url)
                    
                    if files_response.status_code == 200:
                        files_folder = files_response.json()
                        folder_id = files_folder.get('id')
                        
                        if folder_id:
                            children_url = f"https://graph.microsoft.com/v1.0/me/drive/items/{folder_id}/children"
                            children_response = await client.get(children_url)
                            
                            if children_response.status_code == 200:
                                files = children_response.json().get('value', [])
                                if files:
                                    channel_data['files'] = files
                                    logging.info(f"       {len(files)} files")
                except Exception as e:
                    logging.debug(f"Could not fetch files for {channel_name}: {e}")
                
                team_data['channels'].append(channel_data)
                await asyncio.sleep(0.1)
                
            except httpx.HTTPStatusError as e:
                if e.response.status_code == 403:
                    logging.warning(f"      Access denied to channel: {channel_name}")
                else:
                    logging.error(f" Error fetching messages from {channel_name}: {e}")
                continue
        
        return team_data if team_data['channels'] else None
    
    except httpx.HTTPStatusError as e:
        if e.response.status_code == 403:
            logging.warning(f" Access denied to team: {team_name}")
        else:
            logging.error(f" Error processing team {team_name}: {e.response.status_code}")
        return None
    except Exception as e:
        logging.error(f" Unexpected error extracting team {team_name}: {e}")
        return None


# ============================================================================
# 2. DATA ANALYTICS
# ============================================================================

def analyze_team_data(team_data: Dict) -> Dict:
    """
    Extract analytics and insights from Teams data.
    
    Extracts:
    - Message volume by channel
    - File counts
    - Active channels
    - Participant counts
    
    Args:
        team_data: Team data from extraction
        
    Returns:
        Analytics dict
    """
    analytics = {
        'total_channels': len(team_data.get('channels', [])),
        'total_messages': 0,
        'total_files': 0,
        'active_channels': [],
        'channel_stats': []
    }
    
    for channel in team_data.get('channels', []):
        channel_name = channel.get('channel_name', 'Unknown')
        message_count = channel.get('message_count', 0)
        file_count = len(channel.get('files', []))
        
        analytics['total_messages'] += message_count
        analytics['total_files'] += file_count
        
        if message_count > 0:
            analytics['active_channels'].append(channel_name)
        
        analytics['channel_stats'].append({
            'name': channel_name,
            'messages': message_count,
            'files': file_count,
            'active': message_count > 0
        })
    
    # Sort by message count
    analytics['channel_stats'].sort(key=lambda x: x['messages'], reverse=True)
    
    return analytics


def calculate_teams_quality_score(team_data: Dict, analytics: Dict) -> int:
    """
    Calculate data quality score (0-100).
    
    Factors:
    - Has multiple channels (20 points)
    - Has messages (40 points)
    - Has files (20 points)
    - Active channels (20 points)
    
    Args:
        team_data: Raw team data
        analytics: Analytics from analyze_team_data
        
    Returns:
        Quality score (0-100)
    """
    score = 0
    
    # Has multiple channels? (20 points)
    channel_count = analytics.get('total_channels', 0)
    if channel_count > 5:
        score += 20
    elif channel_count > 2:
        score += 15
    elif channel_count > 0:
        score += 10
    
    # Has messages? (40 points)
    message_count = analytics.get('total_messages', 0)
    if message_count > 100:
        score += 40
    elif message_count > 50:
        score += 30
    elif message_count > 10:
        score += 20
    elif message_count > 0:
        score += 10
    
    # Has files? (20 points)
    file_count = analytics.get('total_files', 0)
    if file_count > 20:
        score += 20
    elif file_count > 10:
        score += 15
    elif file_count > 0:
        score += 10
    
    # Active channels? (20 points)
    active_count = len(analytics.get('active_channels', []))
    if active_count > 5:
        score += 20
    elif active_count > 2:
        score += 15
    elif active_count > 0:
        score += 10
    
    return min(100, score)


# ============================================================================
# 3. SEARCHABLE TEXT GENERATION
# ============================================================================

def create_teams_searchable_text(
    team_data: Dict,
    analytics: Dict,
    max_messages_per_channel: int = 20
) -> str:
    """
    Create rich, AI-friendly searchable text from Teams data.
    
    Includes:
    - Team overview
    - Channel summaries
    - Sample messages
    - File listings
    
    Args:
        team_data: Raw team data
        analytics: Analytics dict
        max_messages_per_channel: Max messages to include per channel
        
    Returns:
        Formatted searchable text
    """
    parts = []
    
    # Team header
    team_name = team_data.get('team_name', 'Unknown')
    parts.append(f"üë• Microsoft Teams: {team_name}")
    parts.append(f"Channels: {analytics.get('total_channels', 0)}")
    parts.append(f"Messages: {analytics.get('total_messages', 0)}")
    parts.append(f"Files: {analytics.get('total_files', 0)}")
    parts.append("")
    
    # Channel stats
    if analytics.get('channel_stats'):
        parts.append("=== CHANNEL OVERVIEW ===")
        for stat in analytics['channel_stats'][:10]:  # Top 10 channels
            parts.append(f"\n {stat['name']}")
            parts.append(f"   Messages: {stat['messages']}")
            parts.append(f"   Files: {stat['files']}")
            parts.append(f"   Status: {'Active' if stat['active'] else 'Inactive'}")
        parts.append("")
    
    # Sample messages from each channel
    parts.append("=== SAMPLE MESSAGES ===")
    for channel in team_data.get('channels', []):
        channel_name = channel.get('channel_name', 'Unknown')
        messages = channel.get('messages', [])
        
        if messages:
            parts.append(f"\nüí¨ Channel: {channel_name}")
            
            for msg_idx, message in enumerate(messages[:max_messages_per_channel]):
                from_user = message.get('from', {}).get('user', {}).get('displayName', 'Unknown')
                content = message.get('body', {}).get('content', '')
                created = message.get('createdDateTime', '')
                
                # Clean HTML from content (basic)
                import re
                content_clean = re.sub(r'<[^>]+>', '', content)
                content_clean = content_clean.strip()
                
                if content_clean:
                    parts.append(f"  [{from_user}] {content_clean[:200]}...")
        
        parts.append("")
    
    # Files summary
    if analytics.get('total_files', 0) > 0:
        parts.append("=== SHARED FILES ===")
        for channel in team_data.get('channels', []):
            files = channel.get('files', [])
            if files:
                channel_name = channel.get('channel_name', 'Unknown')
                parts.append(f"\nüìÅ {channel_name}:")
                for file in files[:10]:  # First 10 files
                    file_name = file.get('name', 'Unknown')
                    file_size = file.get('size', 0)
                    parts.append(f"   ‚Ä¢ {file_name} ({file_size} bytes)")
        parts.append("")
    
    return "\n".join(parts)


# ============================================================================
# 4. DATA CLEANING
# ============================================================================

def clean_teams_data(team_data: Dict) -> Dict:
    """
    Clean and enrich Teams data.
    
    Removes:
    - Unnecessary metadata
    - Empty content
    
    Adds:
    - Quality score
    - Analytics
    - Searchable text
    - Tags
    
    Args:
        team_data: Raw team data from extraction
        
    Returns:
        Cleaned and enriched team dict
    """
    try:
        # Run analytics
        analytics = analyze_team_data(team_data)
        
        # Calculate quality score
        quality_score = calculate_teams_quality_score(team_data, analytics)
        
        # Create searchable text
        searchable_text = create_teams_searchable_text(team_data, analytics)
        
        # Auto-generate tags
        team_name = team_data.get('team_name', '').lower()
        tags = []
        
        if 'engineering' in team_name or 'dev' in team_name:
            tags.append('engineering')
        if 'sales' in team_name or 'business' in team_name:
            tags.append('sales')
        if 'marketing' in team_name:
            tags.append('marketing')
        if 'executive' in team_name or 'leadership' in team_name:
            tags.append('leadership')
        
        # Build cleaned structure
        cleaned = {
            'team_id': team_data.get('team_id'),
            'team_name': team_data.get('team_name', 'Unknown'),
            'file_type': 'Microsoft Teams',
            'channels': team_data.get('channels', []),
            'analytics': analytics,
            'searchable_text': searchable_text,
            'quality_score': quality_score,
            'total_channels': analytics.get('total_channels', 0),
            'total_messages': analytics.get('total_messages', 0),
            'total_files': analytics.get('total_files', 0),
            'tags': tags if tags else None
        }
        
        return cleaned
        
    except Exception as e:
        logging.error(f" Cleaning error: {e}")
        return {
            'team_name': team_data.get('team_name', 'ERROR'),
            'error': str(e)
        }


# ============================================================================
# 5. MAIN ETL FUNCTION
# ============================================================================

async def run_microsoft_teams_etl(
    user_id: str,
    access_token: str,
    enable_versioning: bool = True
) -> Tuple[bool, int]:
    """
    üî• ULTIMATE Microsoft Teams ETL with ALL features.
    
    Features:
     Team and channel extraction
     Message content extraction
     Shared files metadata
     Analytics and insights
     Search-optimized text generation
     Data quality scoring
    
    Args:
        user_id: User ID
        access_token: Valid Microsoft access token
        enable_versioning: Enable file versioning (default True)
        
    Returns:
        (success: bool, messages_count: int)
    """
    logging.info(f"{'='*70}")
    logging.info(f"üë• ULTIMATE MICROSOFT TEAMS ETL: Starting for user {user_id}")
    logging.info(f"{'='*70}")
    
    try:
        headers = {
            "Authorization": f"Bearer {access_token}",
            "Accept": "application/json"
        }
        
        async with httpx.AsyncClient(headers=headers, timeout=60.0) as client:
            logging.info("üîç Fetching Teams...")
            
            # Get all teams the user is a member of
            teams_url = "https://graph.microsoft.com/v1.0/me/joinedTeams"
            response = await client.get(teams_url)
            response.raise_for_status()
            teams = response.json().get('value', [])
            
            logging.info(f"‚úì Found {len(teams)} teams")
            await update_sync_progress(user_id, "microsoft-teams", progress=f"0/{len(teams)} teams")
            
            bucket_name = "Kogna"
            successful_count = 0
            all_cleaned_teams = []
            
            # Statistics
            stats = {
                'total_teams': len(teams),
                'total_channels': 0,
                'total_messages': 0,
                'total_files': 0
            }
            
            # Process each team
            for idx, team in enumerate(teams):
                team_id = team.get('id')
                team_name = team.get('displayName')
                
                try:
                    logging.info(f"üë• [{idx+1}/{len(teams)}] Processing: {team_name}")
                    
                    # Extract team data
                    team_data = await extract_team_data(client, team_id, team_name)
                    
                    if team_data:
                        # Clean and enrich data
                        cleaned_team = clean_teams_data(team_data)
                        all_cleaned_teams.append(cleaned_team)
                        
                        # Update statistics
                        stats['total_channels'] += cleaned_team.get('total_channels', 0)
                        stats['total_messages'] += cleaned_team.get('total_messages', 0)
                        stats['total_files'] += cleaned_team.get('total_files', 0)
                        
                        # Save individual team
                        file_path = f"{user_id}/microsoft_teams/{team_id}_data.json"
                        cleaned_json = json.dumps(cleaned_team, indent=2)
                        
                        upload_success = await safe_upload_to_bucket(
                            bucket_name,
                            file_path,
                            cleaned_json.encode('utf-8'),
                            "application/json",
                            enable_versioning=enable_versioning
                        )
                        
                        if upload_success:
                            successful_count += 1
                            latest_path = f"{user_id}/microsoft_teams/{team_id}_data_latest.json"
                            queue_embedding(user_id, latest_path)
                            
                            logging.info(f"   ‚úì {cleaned_team.get('total_messages', 0)} messages, {cleaned_team.get('total_files', 0)} files")
                            logging.info(f"   ‚úì Quality: {cleaned_team.get('quality_score', 0)}/100")
                    else:
                        logging.warning(f" No data extracted from team: {team_name}")
                    
                    # Update progress
                    await update_sync_progress(
                        user_id, "microsoft-teams",
                        progress=f"{idx+1}/{len(teams)} teams",
                        files_processed=successful_count
                    )
                    
                    await asyncio.sleep(RATE_LIMIT_DELAY)
                
                except Exception as e:
                    logging.error(f" Error processing {team_name}: {e}")
                    continue
            
            # ================================================================
            # SAVE COMBINED FILE
            # ================================================================
            if all_cleaned_teams:
                combined_data = {
                    'teams': all_cleaned_teams,
                    'metadata': {
                        'total_teams': len(all_cleaned_teams),
                        'extracted_at': int(time.time()),
                        'cleaned': True,
                        'enhanced': True,
                        'statistics': stats
                    }
                }
                
                combined_json = json.dumps(combined_data, indent=2)
                file_path = f"{user_id}/microsoft_teams/all_teams.json"
                
                await safe_upload_to_bucket(
                    bucket_name,
                    file_path,
                    combined_json.encode('utf-8'),
                    "application/json",
                    enable_versioning=True
                )
                
                combined_file_path = f"{user_id}/microsoft_teams/all_teams_latest.json"
                queue_embedding(user_id, combined_file_path)
            
            # ================================================================
            # FINAL REPORT
            # ================================================================
            logging.info(f"{'='*70}")
            logging.info(f" ULTIMATE TEAMS ETL COMPLETE")
            logging.info(f"{'='*70}")
            logging.info(f" Statistics:")
            logging.info(f"   Teams processed: {successful_count}/{len(teams)}")
            logging.info(f"   Total channels: {stats['total_channels']}")
            logging.info(f"   Total messages: {stats['total_messages']}")
            logging.info(f"   Total files: {stats['total_files']}")
            logging.info(f"{'='*70}")
            
            return True, stats['total_messages']
    
    except httpx.HTTPStatusError as e:
        logging.error(f" API Error {e.response.status_code}: {e.response.text}")
        
        if e.response.status_code == 403:
            logging.error(" Permission error. Required scopes:")
            logging.error("   - Team.ReadBasic.All")
            logging.error("   - Channel.ReadBasic.All")
            logging.error("   - ChannelMessage.Read.All")
            logging.error("   - Files.Read.All")
        
        return False, 0
    except Exception as e:
        logging.error(f" Microsoft Teams ETL Error: {e}")
        import traceback
        traceback.print_exc()
        return False, 0


# ============================================================================
# EXPORTS
# ============================================================================

__all__ = [
    'run_microsoft_teams_etl',
    'extract_team_data',
    'analyze_team_data',
    'clean_teams_data',
    'create_teams_searchable_text'
]