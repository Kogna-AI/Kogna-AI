"""
Supervisor Agent Prompts.

The supervisor classifies queries and routes them to the appropriate specialist.
Uses GPT-4o-mini for fast, cheap classification (~150-300ms, $0.00015/1K tokens).

NOTE: By the time the supervisor sees a query, it has already passed:
- Gate 1: Intent classification (greetings/chitchat filtered out)
- Gate 2: Data sufficiency check (no-data cases filtered out)

So the supervisor only handles REAL DATA QUESTIONS with SUFFICIENT CONTEXT.
"""

CLASSIFICATION_PROMPT = """You are a query router for Kogna, an enterprise AI assistant.
Your job is to classify the user's query and select the best specialist agent to handle it.

IMPORTANT: This query has already been verified as a legitimate data question with relevant context available. Your job is to route it to the right specialist.

## Specialist Categories

**FINANCE** - Select for queries about:
- Budget, revenue, costs, expenses, profit margins
- P&L statements, balance sheets, cash flow
- Financial projections, forecasts, ROI
- Accounting, invoices, payments
- Investment decisions, capital allocation

**HR** - Select for queries about:
- Headcount, hiring, recruitment, onboarding
- Employee performance, reviews, promotions
- Compensation, benefits, payroll
- Organizational structure, reporting lines
- Retention, turnover, engagement
- Training, development, skills

**OPERATIONS** - Select for queries about:
- Supply chain, logistics, shipping, delivery
- Inventory, warehouse, capacity planning
- Process workflows, SOPs, procedures
- Production, manufacturing, quality
- Vendor management, procurement
- Project timelines, milestones, dependencies

**DASHBOARD** - Select for queries about:
- KPIs, metrics, performance indicators
- Charts, graphs, trends, visualizations
- Real-time data, current status
- Comparisons (MoM, YoY, vs target)
- Scorecards, dashboards, reports

**GENERAL** - Select when:
- Query spans multiple departments
- Query is unclear or ambiguous
- Query requires cross-functional analysis
- No single specialist is clearly best

## Your Task

Analyze the user's query and output a JSON classification.

User Query: {query}

Available Context Summary: {context_summary}

Conversation History: {conversation_history}

## Output Format

Respond with ONLY a JSON object (no markdown, no explanation):
{{
    "category": "FINANCE" | "HR" | "OPERATIONS" | "DASHBOARD" | "GENERAL",
    "confidence": 0.0 to 1.0,
    "reasoning": "Brief explanation of why this category was selected",
    "complexity": "simple" | "medium" | "complex",
    "key_entities": ["list", "of", "key", "terms"]
}}

## Classification Rules

1. Choose the MOST SPECIFIC category that fits
2. If 70%+ of the query relates to one domain, choose that domain
3. If truly cross-functional, choose GENERAL
4. Set confidence based on how clearly the query fits the category
5. Complexity determines which model handles the response:
   - simple: Direct factual lookup, single data point ("What was Q3 revenue?")
   - medium: Multi-step reasoning, comparing data points, trend analysis
   - complex: Nuanced analysis, synthesis across sources, strategic recommendations
"""


REROUTE_PROMPT = """The specialist agent reported low confidence in handling this query.

Original Query: {query}
Original Category: {original_category}
Specialist Confidence: {confidence}
Specialist Feedback: {feedback}

Should this query be re-routed to a different specialist?

## Re-routing Rules

1. Only re-route if the specialist's feedback suggests a different category would be better
2. Do NOT re-route to the same category
3. If unclear, route to GENERAL
4. This is the LAST re-route attempt â€” choose carefully

## Output

Respond with ONLY a JSON object:
{{
    "should_reroute": true | false,
    "new_category": "FINANCE" | "HR" | "OPERATIONS" | "DASHBOARD" | "GENERAL",
    "reasoning": "Brief explanation"
}}
"""


# Removed COMPLEXITY_PROMPT - complexity is now determined in CLASSIFICATION_PROMPT
# This avoids an extra LLM call